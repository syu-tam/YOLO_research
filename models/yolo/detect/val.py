# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import os
from pathlib import Path

import numpy as np
import torch

from data import build_dataloader, build_yolo_dataset, converter
from engine.validator import BaseValidator
from utils import LOGGER, ops
from utils.checks import check_requirements
from utils.ops import non_max_suppression
from utils.metrics import ConfusionMatrix, DetMetrics, box_iou
from utils.plotting import output_to_target, plot_images


class DetectionValidator(BaseValidator):
    # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦æ¤œè¨¼ã™ã‚‹ãŸã‚ã®BaseValidatorã‚¯ãƒ©ã‚¹ã‚’æ‹¡å¼µã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    #
    # ä¾‹:
    #     ```python
    #     from models.yolo.detect import DetectionValidator
    #
    #     args = dict(model="yolo11n.pt", data="coco8.yaml")
    #     validator = DetectionValidator(args=args)
    #     validator()
    #     ```

    def __init__(self, dataloader=None, save_dir=None, pbar=None, args=None, _callbacks=None):
        """Initialize detection model with necessary variables and settings."""
        # å¿…è¦ãªå¤‰æ•°ã¨è¨­å®šã‚’ä½¿ç”¨ã—ã¦æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        super().__init__(dataloader, save_dir, pbar, args, _callbacks)  # è¦ªã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
        self.nt_per_class = None  # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°
        self.nt_per_image = None  # ç”»åƒã”ã¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°
        self.is_coco = False  # COCOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã©ã†ã‹
        self.is_lvis = False  # LVISãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã©ã†ã‹
        self.class_map = None  # ã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ—
        self.args.task = "detect"  # ã‚¿ã‚¹ã‚¯ã‚’æ¤œå‡ºã«è¨­å®š
        self.metrics = DetMetrics(save_dir=self.save_dir, on_plot=self.on_plot)  # æ¤œå‡ºãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆæœŸåŒ–
        self.iouv = torch.linspace(0.5, 0.95, 10)  # IoU vector for mAP@0.5:0.95ã€‚mAP@0.5:0.95ã®IoUãƒ™ã‚¯ãƒˆãƒ«
        self.niou = self.iouv.numel()  # IoUãƒ™ã‚¯ãƒˆãƒ«æ•°
        self.lb = []  # for autolabellingã€‚è‡ªå‹•ãƒ©ãƒ™ãƒ«ä»˜ã‘ç”¨
        if self.args.save_hybrid:  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ä¿å­˜ãŒTrueã®å ´åˆ
            LOGGER.warning(
                "WARNING âš ï¸ 'save_hybrid=True' will append ground truth to predictions for autolabelling.\n"
                "WARNING âš ï¸ 'save_hybrid=True' will cause incorrect mAP.\n"
            )  # è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›

    def preprocess(self, batch):
        """Preprocesses batch of images for YOLO training."""
        # YOLOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ç”»åƒã®ãƒãƒƒãƒã‚’å‰å‡¦ç†ã—ã¾ã™ã€‚
        batch["img"] = batch["img"].to(self.device, non_blocking=True)  # ç”»åƒã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
        batch["img"] = (batch["img"].half() if self.args.half else batch["img"].float()) / 255  # ç”»åƒã‚’floatã«å¤‰æ›ã—ã¦æ­£è¦åŒ–
        for k in ["batch_idx", "cls", "bboxes"]:  # ã‚­ãƒ¼ã‚’åå¾©å‡¦ç†
            batch[k] = batch[k].to(self.device)  # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•

        if self.args.save_hybrid:  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ä¿å­˜ãŒTrueã®å ´åˆ
            height, width = batch["img"].shape[2:]  # é«˜ã•ã€å¹…
            nb = len(batch["img"])  # ãƒãƒƒãƒã‚µã‚¤ã‚º
            bboxes = batch["bboxes"] * torch.tensor((width, height, width, height), device=self.device)  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            self.lb = [
                torch.cat([batch["cls"][batch["batch_idx"] == i], bboxes[batch["batch_idx"] == i]], dim=-1)
                for i in range(nb)
            ]  # ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ

        return batch  # ãƒãƒƒãƒã‚’è¿”ã™

    def init_metrics(self, model):
        """Initialize evaluation metrics for YOLO."""
        # YOLOã®è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        val = self.data.get(self.args.split, "")  # validation pathã€‚æ¤œè¨¼ãƒ‘ã‚¹
        self.is_coco = (  # COCOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã©ã†ã‹
            isinstance(val, str)
            and "coco" in val
            and (val.endswith(f"{os.sep}val2017.txt") or val.endswith(f"{os.sep}test-dev2017.txt"))
        )  # is COCO
        self.is_lvis = isinstance(val, str) and "lvis" in val and not self.is_coco  # is LVISã€‚LVISãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã©ã†ã‹
        self.class_map = converter.coco80_to_coco91_class() if self.is_coco else list(range(len(model.names)))  # ã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ—ã‚’åˆæœŸåŒ–
        self.args.save_json |= self.args.val and (self.is_coco or self.is_lvis) and not self.training  # run final valã€‚æœ€çµ‚æ¤œè¨¼ã‚’å®Ÿè¡Œ
        self.names = model.names  # åå‰ã‚’è¨­å®š
        self.nc = len(model.names)  # ã‚¯ãƒ©ã‚¹æ•°ã‚’è¨­å®š
        self.metrics.names = self.names  # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åå‰ã‚’è¨­å®š
        self.metrics.plot = self.args.plots  # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’è¨­å®š
        self.confusion_matrix = ConfusionMatrix(nc=self.nc, conf=self.args.conf)  # æ··åŒè¡Œåˆ—ã‚’åˆæœŸåŒ–
        self.seen = 0  # ã‚·ãƒ¼ãƒ³ã‚’0ã«è¨­å®š
        self.jdict = []  # JDictã‚’åˆæœŸåŒ–
        self.stats = dict(tp=[], conf=[], pred_cls=[], target_cls=[], target_img=[])  # çµ±è¨ˆã‚’åˆæœŸåŒ–

    def get_desc(self):
        """Return a formatted string summarizing class metrics of YOLO model."""
        # YOLOãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ©ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¦ç´„ã™ã‚‹æ›¸å¼è¨­å®šã•ã‚ŒãŸæ–‡å­—åˆ—ã‚’è¿”ã—ã¾ã™ã€‚
        return ("%22s" + "%11s" * 6) % ("Class", "Images", "Instances", "Box(P", "R", "mAP50", "mAP50-95)")  # æ–‡å­—åˆ—ã‚’è¿”ã™

    def postprocess(self, preds):
        """Apply Non-maximum suppression to prediction outputs."""
        # éæœ€å¤§æŠ‘åˆ¶ã‚’äºˆæ¸¬å‡ºåŠ›ã«é©ç”¨ã—ã¾ã™ã€‚

        return non_max_suppression(
            preds,
            self.args.conf,
            self.args.iou,
            labels=self.lb,
            multi_label=True,
            agnostic=self.args.single_cls or self.args.agnostic_nms,
            max_det=self.args.max_det,
        )  # NMSã‚’é©ç”¨

    def _prepare_batch(self, si, batch):
        """Prepares a batch of images and annotations for validation."""
        # æ¤œè¨¼ç”¨ã«ç”»åƒã®ãƒãƒƒãƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æº–å‚™ã—ã¾ã™ã€‚
        idx = batch["batch_idx"] == si  # ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        cls = batch["cls"][idx].squeeze(-1)  # ã‚¯ãƒ©ã‚¹
        bbox = batch["bboxes"][idx]  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        ori_shape = batch["ori_shape"][si]  # å…ƒã®å½¢çŠ¶
        imgsz = batch["img"].shape[2:]  # ç”»åƒã‚µã‚¤ã‚º
        ratio_pad = batch["ratio_pad"][si]  # å‰²åˆã¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        if len(cls):  # ã‚¯ãƒ©ã‚¹ãŒã‚ã‚‹å ´åˆ
            bbox = ops.xywh2xyxy(bbox) * torch.tensor(imgsz, device=self.device)[[1, 0, 1, 0]]  # target boxesã€‚ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒœãƒƒã‚¯ã‚¹
            ops.scale_boxes(imgsz, bbox, ori_shape, ratio_pad=ratio_pad)  # native-space labelsã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒšãƒ¼ã‚¹ãƒ©ãƒ™ãƒ«
        return {"cls": cls, "bbox": bbox, "ori_shape": ori_shape, "imgsz": imgsz, "ratio_pad": ratio_pad}  # è¾æ›¸ã‚’è¿”ã™

    def _prepare_pred(self, pred, pbatch):
        """Prepares a batch of images and annotations for validation."""
        # æ¤œè¨¼ç”¨ã«ç”»åƒã®ãƒãƒƒãƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æº–å‚™ã—ã¾ã™ã€‚
        predn = pred.clone()  # è¤‡è£½ã‚’ä½œæˆ
        ops.scale_boxes(
            pbatch["imgsz"], predn[:, :4], pbatch["ori_shape"], ratio_pad=pbatch["ratio_pad"]
        )  # native-space predã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒšãƒ¼ã‚¹äºˆæ¸¬
        return predn  # è¤‡è£½ã‚’è¿”ã™

    def update_metrics(self, preds, batch):
        """Metrics."""
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‚
        for si, pred in enumerate(preds):  # äºˆæ¸¬ã‚’åå¾©å‡¦ç†
            self.seen += 1  # å‚ç…§ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
            npr = len(pred)  # äºˆæ¸¬æ•°
            stat = dict(  # çµ±è¨ˆã‚’åˆæœŸåŒ–
                conf=torch.zeros(0, device=self.device),  # ä¿¡é ¼åº¦
                pred_cls=torch.zeros(0, device=self.device),  # äºˆæ¸¬ã‚¯ãƒ©ã‚¹
                tp=torch.zeros(npr, self.niou, dtype=torch.bool, device=self.device),  # çœŸé™½æ€§
            )
            pbatch = self._prepare_batch(si, batch)  # ãƒãƒƒãƒã‚’æº–å‚™
            cls, bbox = pbatch.pop("cls"), pbatch.pop("bbox")  # ã‚¯ãƒ©ã‚¹ã¨ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—
            nl = len(cls)  # ãƒ©ãƒ™ãƒ«æ•°
            stat["target_cls"] = cls  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚’è¨­å®š
            stat["target_img"] = cls.unique()  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã‚’è¨­å®š
            if npr == 0:  # äºˆæ¸¬ãŒãªã„å ´åˆ
                if nl:  # ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹å ´åˆ
                    for k in self.stats.keys():  # çµ±è¨ˆã‚’åå¾©å‡¦ç†
                        self.stats[k].append(stat[k])  # çµ±è¨ˆã‚’è¿½åŠ 
                    if self.args.plots:  # ãƒ—ãƒ­ãƒƒãƒˆãŒTrueã®å ´åˆ
                        self.confusion_matrix.process_batch(detections=None, gt_bboxes=bbox, gt_cls=cls)  # æ··åŒè¡Œåˆ—ã‚’å‡¦ç†
                continue  # æ¬¡ã®ç”»åƒã¸

            # Predictions
            if self.args.single_cls:  # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ãƒ©ã‚¹ã®å ´åˆ
                pred[:, 5] = 0  # ã‚¯ãƒ©ã‚¹ã‚’0ã«è¨­å®š
            predn = self._prepare_pred(pred, pbatch)  # äºˆæ¸¬ã‚’æº–å‚™
            stat["conf"] = predn[:, 4]  # ä¿¡é ¼åº¦ã‚’è¨­å®š
            stat["pred_cls"] = predn[:, 5]  # äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã‚’è¨­å®š

            # Evaluate
            if nl:  # ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹å ´åˆ
                stat["tp"] = self._process_batch(predn, bbox, cls)  # çœŸé™½æ€§ã‚’å‡¦ç†
                if self.args.plots:  # ãƒ—ãƒ­ãƒƒãƒˆãŒTrueã®å ´åˆ
                    self.confusion_matrix.process_batch(predn, bbox, cls)  # æ··åŒè¡Œåˆ—ã‚’å‡¦ç†
            for k in self.stats.keys():  # çµ±è¨ˆã‚’åå¾©å‡¦ç†
                self.stats[k].append(stat[k])  # çµ±è¨ˆã‚’è¿½åŠ 

            # Save
            if self.args.save_json:  # JSONã‚’ä¿å­˜ã™ã‚‹å ´åˆ
                self.pred_to_json(predn, batch["im_file"][si])  # äºˆæ¸¬ã‚’JSONã«å¤‰æ›
            if self.args.save_txt:  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹å ´åˆ
                self.save_one_txt(
                    predn,
                    self.args.save_conf,
                    pbatch["ori_shape"],
                    self.save_dir / "labels" / f'{Path(batch["im_file"][si]).stem}.txt',
                )  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜

    def finalize_metrics(self, *args, **kwargs):
        """Set final values for metrics speed and confusion matrix."""
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é€Ÿåº¦ã¨æ··åŒè¡Œåˆ—ã®æœ€çµ‚å€¤ã‚’è¨­å®šã—ã¾ã™ã€‚
        self.metrics.speed = self.speed  # é€Ÿåº¦ã‚’è¨­å®š
        self.metrics.confusion_matrix = self.confusion_matrix  # æ··åŒè¡Œåˆ—ã‚’è¨­å®š

    def get_stats(self):
        """Returns metrics statistics and results dictionary."""
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çµ±è¨ˆã¨çµæœè¾æ›¸ã‚’è¿”ã—ã¾ã™ã€‚
        stats = {k: torch.cat(v, 0).cpu().numpy() for k, v in self.stats.items()}  # to numpyã€‚numpyã«å¤‰æ›
        self.nt_per_class = np.bincount(stats["target_cls"].astype(int), minlength=self.nc)  # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°
        self.nt_per_image = np.bincount(stats["target_img"].astype(int), minlength=self.nc)  # ç”»åƒã”ã¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°
        stats.pop("target_img", None)  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã‚’å‰Šé™¤
        if len(stats) and stats["tp"].any():  # çµ±è¨ˆãŒã‚ã‚Šã€çœŸé™½æ€§ãŒã‚ã‚‹å ´åˆ
            self.metrics.process(**stats)  # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å‡¦ç†
        return self.metrics.results_dict  # çµæœè¾æ›¸ã‚’è¿”ã™

    def print_results(self):
        """Prints training/validation set metrics per class."""
        # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚
        pf = "%22s" + "%11i" * 2 + "%11.3g" * len(self.metrics.keys)  # print formatã€‚å°åˆ·å½¢å¼
        LOGGER.info(pf % ("all", self.seen, self.nt_per_class.sum(), *self.metrics.mean_results()))  # ãƒ­ã‚°ã‚’å‡ºåŠ›
        if self.nt_per_class.sum() == 0:  # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°ã®åˆè¨ˆãŒ0ã®å ´åˆ
            LOGGER.warning(f"WARNING âš ï¸ no labels found in {self.args.task} set, can not compute metrics without labels")  # è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›

        # Print results per class
        if self.args.verbose and not self.training and self.nc > 1 and len(self.stats):  # è©³ç´°ãƒ¢ãƒ¼ãƒ‰ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã¯ãªã„ã€ã‚¯ãƒ©ã‚¹æ•°ãŒ1ã‚ˆã‚Šå¤§ãã„ã€çµ±è¨ˆãŒã‚ã‚‹å ´åˆ
            for i, c in enumerate(self.metrics.ap_class_index):  # ã‚¯ãƒ©ã‚¹ã‚’åå¾©å‡¦ç†
                LOGGER.info(
                    pf % (self.names[c], self.nt_per_image[c], self.nt_per_class[c], *self.metrics.class_result(i))
                )  # ãƒ­ã‚°ã‚’å‡ºåŠ›

        if self.args.plots:  # ãƒ—ãƒ­ãƒƒãƒˆãŒTrueã®å ´åˆ
            for normalize in True, False:  # æ­£è¦åŒ–ã‚’åå¾©å‡¦ç†
                self.confusion_matrix.plot(
                    save_dir=self.save_dir, names=self.names.values(), normalize=normalize, on_plot=self.on_plot
                )  # æ··åŒè¡Œåˆ—ã‚’ãƒ—ãƒ­ãƒƒãƒˆ

    def _process_batch(self, detections, gt_bboxes, gt_cls):
        # æ­£ã—ã„äºˆæ¸¬è¡Œåˆ—ã‚’è¿”ã—ã¾ã™ã€‚
        #
        # å¼•æ•°ï¼š
        #     detections (torch.Tensor): å„æ¤œå‡ºãŒ(x1ã€y1ã€x2ã€y2ã€confã€ã‚¯ãƒ©ã‚¹)ã§ã‚ã‚‹æ¤œå‡ºã‚’è¡¨ã™å½¢çŠ¶(Nã€6)ã®ãƒ†ãƒ³ã‚½ãƒ«ã€‚
        #     gt_bboxes (torch.Tensor): ã‚°ãƒ©ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹åº§æ¨™ã‚’è¡¨ã™å½¢çŠ¶(Mã€4)ã®ãƒ†ãƒ³ã‚½ãƒ«ã€‚å„ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å½¢å¼ã¯(x1ã€y1ã€x2ã€y2)ã§ã™ã€‚
        #     gt_cls (torch.Tensor): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¡¨ã™å½¢çŠ¶(M,)ã®ãƒ†ãƒ³ã‚½ãƒ«ã€‚
        #
        # æˆ»ã‚Šå€¤ï¼š
        #     (torch.Tensor): 10å€‹ã®IoUãƒ¬ãƒ™ãƒ«ã«å¯¾ã™ã‚‹å½¢çŠ¶(Nã€10)ã®æ­£ã—ã„äºˆæ¸¬è¡Œåˆ—ã€‚
        #
        # æ³¨ï¼š
        #     ã“ã®é–¢æ•°ã¯ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯è¨ˆç®—ã«ç›´æ¥ä½¿ç”¨ã§ãã‚‹å€¤ã‚’è¿”ã—ã¾ã›ã‚“ã€‚ä»£ã‚ã‚Šã«ã€ã‚°ãƒ©ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ä¸­é–“è¡¨ç¾ã‚’æä¾›ã—ã¾ã™ã€‚
        iou = box_iou(gt_bboxes, detections[:, :4])  # IoUã‚’è¨ˆç®—
        return self.match_predictions(detections[:, 5], gt_cls, iou)  # äºˆæ¸¬ã‚’ç…§åˆ

    def build_dataset(self, img_path, mode="val", batch=None):
        # YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
        #
        # å¼•æ•°ï¼š
        #     img_path (str): ç”»åƒã‚’å«ã‚€ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹ã€‚
        #     mode (str): ã€Œtrainã€ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯ã€Œvalã€ãƒ¢ãƒ¼ãƒ‰ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å„ãƒ¢ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ç•°ãªã‚‹æ‹¡å¼µæ©Ÿèƒ½ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚
        #     batch (int, optional): ãƒãƒƒãƒã®ã‚µã‚¤ã‚ºã€‚ã€Œrectã€ç”¨ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Noneã§ã™ã€‚
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, stride=self.stride)  # YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¦è¿”ã™

    def get_dataloader(self, dataset_path, batch_size):
        """Construct and return dataloader."""
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¦è¿”ã—ã¾ã™ã€‚
        dataset = self.build_dataset(dataset_path, batch=batch_size, mode="val")  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰
        return build_dataloader(dataset, batch_size, self.args.workers, shuffle=False, rank=-1)  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¦è¿”ã™

    def plot_val_samples(self, batch, ni):
        """Plot validation image samples."""
        # æ¤œè¨¼ç”»åƒã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚
        plot_images(
            batch["img"],
            batch["batch_idx"],
            batch["cls"].squeeze(-1),
            batch["bboxes"],
            paths=batch["im_file"],
            fname=self.save_dir / f"val_batch{ni}_labels.jpg",
            names=self.names,
            on_plot=self.on_plot,
        )  # ç”»åƒã‚’ãƒ—ãƒ­ãƒƒãƒˆ

    def plot_predictions(self, batch, preds, ni):
        """Plots predicted bounding boxes on input images and saves the result."""
        # å…¥åŠ›ç”»åƒã«äºˆæ¸¬ã•ã‚ŒãŸãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã€çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚
        plot_images(
            batch["img"],
            *output_to_target(preds, max_det=self.args.max_det),
            paths=batch["im_file"],
            fname=self.save_dir / f"val_batch{ni}_pred.jpg",
            names=self.names,
            on_plot=self.on_plot,
        )  # pred

    def save_one_txt(self, predn, save_conf, shape, file):
        """Save YOLO detections to a txt file in normalized coordinates in a specific format."""
        # ç‰¹å®šã®å½¢å¼ã§ã€æ­£è¦åŒ–ã•ã‚ŒãŸåº§æ¨™ã§YOLOæ¤œå‡ºã‚’txtãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚
        from engine.results import Results  # çµæœã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

        Results(
            np.zeros((shape[0], shape[1]), dtype=np.uint8),
            path=None,
            names=self.names,
            boxes=predn[:, :6],
        ).save_txt(file, save_conf=save_conf)  # txtãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

    def pred_to_json(self, predn, filename):
        """Serialize YOLO predictions to COCO json format."""
        # YOLOäºˆæ¸¬ã‚’COCO jsonå½¢å¼ã«ã‚·ãƒªã‚¢ãƒ«åŒ–ã—ã¾ã™ã€‚
        stem = Path(filename).stem  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        image_id = int(stem) if stem.isnumeric() else stem  # ç”»åƒIDã‚’è¨­å®š
        box = ops.xyxy2xywh(predn[:, :4])  # xywhã«å¤‰æ›
        box[:, :2] -= box[:, 2:] / 2  # xy center to top-left cornerã€‚ä¸­å¿ƒã‚’å·¦ä¸Šéš…ã«ç§»å‹•
        for p, b in zip(predn.tolist(), box.tolist()):  # äºˆæ¸¬ã¨ãƒœãƒƒã‚¯ã‚¹ã‚’åå¾©å‡¦ç†
            self.jdict.append(  # JSONãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã«è¿½åŠ 
                {
                    "image_id": image_id,  # ç”»åƒID
                    "category_id": self.class_map[int(p[5])]
                    + (1 if self.is_lvis else 0),  # index starts from 1 if it's lvisã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯lvisã®å ´åˆã¯1ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™
                    "bbox": [round(x, 3) for x in b],  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
                    "score": round(p[4], 5),  # ã‚¹ã‚³ã‚¢
                }
            )

    def eval_json(self, stats):
        """Evaluates YOLO output in JSON format and returns performance statistics."""
        # JSONå½¢å¼ã§YOLOå‡ºåŠ›ã‚’è©•ä¾¡ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’è¿”ã—ã¾ã™ã€‚
        if self.args.save_json and (self.is_coco or self.is_lvis) and len(self.jdict):  # JSONã‚’ä¿å­˜ã€COCOã¾ãŸã¯LVISã€jdictãŒã‚ã‚‹å ´åˆ
            pred_json = self.save_dir / "predictions.json"  # predictionsã€‚äºˆæ¸¬
            anno_json = (
                self.data["path"]
                / "annotations"
                / ("instances_val2017.json" if self.is_coco else f"lvis_v1_{self.args.split}.json")
            )  # annotationsã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
            pkg = "pycocotools" if self.is_coco else "lvis"  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å
            LOGGER.info(f"\nEvaluating {pkg} mAP using {pred_json} and {anno_json}...")  # ãƒ­ã‚°ã‚’å‡ºåŠ›
            try:  # ä¾‹å¤–å‡¦ç†
                for x in pred_json, anno_json:  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åå¾©å‡¦ç†
                    assert x.is_file(), f"{x} file not found"  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                check_requirements("pycocotools>=2.0.6" if self.is_coco else "lvis>=0.5.3")  # è¦ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
                if self.is_coco:  # COCOã®å ´åˆ
                    from pycocotools.coco import COCO  # noqa
                    from pycocotools.cocoeval import COCOeval  # noqa

                    anno = COCO(str(anno_json))  # init annotations apiã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³APIã‚’åˆæœŸåŒ–
                    pred = anno.loadRes(str(pred_json))  # init predictions api (must pass string, not Path)ã€‚äºˆæ¸¬APIã‚’åˆæœŸåŒ–
                    val = COCOeval(anno, pred, "bbox")  # COCOè©•ä¾¡ã‚’åˆæœŸåŒ–
                else:  # LVISã®å ´åˆ
                    from lvis import LVIS, LVISEval

                    anno = LVIS(str(anno_json))  # init annotations apiã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³APIã‚’åˆæœŸåŒ–
                    pred = anno._load_json(str(pred_json))  # init predictions api (must pass string, not Path)ã€‚äºˆæ¸¬APIã‚’åˆæœŸåŒ–
                    val = LVISEval(anno, pred, "bbox")  # LVISè©•ä¾¡ã‚’åˆæœŸåŒ–
                val.params.imgIds = [int(Path(x).stem) for x in self.dataloader.dataset.im_files]  # images to evalã€‚è©•ä¾¡ã™ã‚‹ç”»åƒ
                val.evaluate()  # è©•ä¾¡
                val.accumulate()  # è“„ç©
                val.summarize()  # è¦ç´„
                if self.is_lvis:  # LVISã®å ´åˆ
                    val.print_results()  # explicitly call print_resultsã€‚æ˜ç¤ºçš„ã«print_resultsã‚’å‘¼ã³å‡ºã™
                # update mAP50-95 and mAP50
                stats[self.metrics.keys[-1]], stats[self.metrics.keys[-2]] = (
                    val.stats[:2] if self.is_coco else [val.results["AP50"], val.results["AP"]]
                )  # çµ±è¨ˆã‚’æ›´æ–°
            except Exception as e:  # ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆ
                LOGGER.warning(f"{pkg} unable to run: {e}")  # è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›
        return stats  # çµ±è¨ˆã‚’è¿”ã™