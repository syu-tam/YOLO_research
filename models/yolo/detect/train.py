# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import math  # æ•°å­¦é–¢æ•°ã‚’æä¾›ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import random  # ä¹±æ•°ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from copy import copy  # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

import numpy as np  # æ•°å€¤è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import torch.nn as nn  # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

from data import build_dataloader, build_yolo_dataset  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from engine.trainer import BaseTrainer  # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åŸºæœ¬ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from models import yolo  # yoloãƒ¢ãƒ‡ãƒ«é–¢é€£ã®ã‚‚ã®ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from nn.tasks import DetectionModel  # DetectionModelã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils import LOGGER, RANK  # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã¨å®šæ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.plotting import plot_images, plot_labels, plot_results  # ãƒ—ãƒ­ãƒƒãƒˆé–¢é€£ã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.torch_utils import de_parallel, torch_distributed_zero_first  # åˆ†æ•£å­¦ç¿’é–¢é€£ã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ


class DetectionTrainer(BaseTrainer):
    # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®BaseTrainerã‚¯ãƒ©ã‚¹ã‚’æ‹¡å¼µã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    # ä¾‹ï¼š
    #     ```python
    #     from models.yolo.detect import DetectionTrainer
    #
    #     args = dict(model="yolo11n.pt", data="coco8.yaml", epochs=3)
    #     trainer = DetectionTrainer(overrides=args)
    #     trainer.train()
    #     ```

    def build_dataset(self, img_path, mode="train", batch=None):
        # YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
        #
        # å¼•æ•°ï¼š
        #     img_path (str): ç”»åƒã‚’å«ã‚€ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹ã€‚
        #     mode (str): ã€Œtrainã€ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯ã€Œvalã€ãƒ¢ãƒ¼ãƒ‰ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å„ãƒ¢ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ç•°ãªã‚‹æ‹¡å¼µæ©Ÿèƒ½ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚
        #     batch (int, optional): ãƒãƒƒãƒã®ã‚µã‚¤ã‚ºã€‚ã€Œrectã€ç”¨ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Noneã§ã™ã€‚
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)  # ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)  # YOLOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¦è¿”ã™

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¦è¿”ã—ã¾ã™ã€‚
        assert mode in {"train", "val"}, f"Mode must be 'train' or 'val', not {mode}."  # ãƒ¢ãƒ¼ãƒ‰ãŒtrainã¾ãŸã¯valã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDPã€‚DDPã®å ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®*.cacheã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–
            dataset = self.build_dataset(dataset_path, mode, batch_size)  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰
        shuffle = mode == "train"  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        if getattr(dataset, "rect", False) and shuffle:  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒrectã§ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã®å ´åˆ
            LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False")  # è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›
            shuffle = False  # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚’ç„¡åŠ¹åŒ–
        workers = self.args.workers if mode == "train" else self.args.workers * 2  # ãƒ¯ãƒ¼ã‚«æ•°ã‚’è¨­å®š
        return build_dataloader(dataset, batch_size, workers, shuffle, rank)  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¦è¿”ã™

    def preprocess_batch(self, batch):
        # ç”»åƒã®ãƒãƒƒãƒã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦floatã«å¤‰æ›ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€å‰å‡¦ç†ã—ã¾ã™ã€‚
        batch["img"] = batch["img"].to(self.device, non_blocking=True).float() / 255  # ç”»åƒã‚’ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€ã—ã¦æ­£è¦åŒ–
        if self.args.multi_scale:  # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
            imgs = batch["img"]  # ç”»åƒã‚’å–å¾—
            sz = (
                random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                // self.stride
                * self.stride
            )  # sizeã€‚ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã™ã‚‹ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
            sf = sz / max(imgs.shape[2:])  # scale factorã€‚ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚’è¨ˆç®—
            if sf != 1:  # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãŒ1ã§ãªã„å ´åˆ
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs.shape[2:]
                ]  # new shape (stretched to gs-multiple)ã€‚æ–°ã—ã„å½¢çŠ¶ã‚’è¨ˆç®—
                imgs = nn.functional.interpolate(imgs, size=ns, mode="bilinear", align_corners=False)  # ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
            batch["img"] = imgs  # ç”»åƒã‚’æ›´æ–°
        return batch  # æ›´æ–°ã•ã‚ŒãŸãƒãƒƒãƒã‚’è¿”ã™

    def set_model_attributes(self):
        """Nl = de_parallel(self.model).model[-1].nl  # number of detection layers (to scale hyps)."""
        # self.args.box *= 3 / nl  # scale to layers
        # self.args.cls *= self.data["nc"] / 80 * 3 / nl  # scale to classes and layers
        # self.args.cls *= (self.args.imgsz / 640) ** 2 * 3 / nl  # scale to image size and layers
        self.model.nc = self.data["nc"]  # attach number of classes to modelã€‚ãƒ¢ãƒ‡ãƒ«ã«ã‚¯ãƒ©ã‚¹æ•°ã‚’ã‚¢ã‚¿ãƒƒãƒ
        self.model.names = self.data["names"]  # attach class names to modelã€‚ãƒ¢ãƒ‡ãƒ«ã«ã‚¯ãƒ©ã‚¹åã‚’ã‚¢ã‚¿ãƒƒãƒ
        self.model.args = self.args  # attach hyperparameters to modelã€‚ãƒ¢ãƒ‡ãƒ«ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¢ã‚¿ãƒƒãƒ
        # TODO: self.model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc

    def get_model(self, cfg=None, weights=None, verbose=True):
        # YOLOæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚
        model = DetectionModel(cfg, nc=self.data["nc"], verbose=verbose and RANK == -1)  # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        if weights:  # é‡ã¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
            model.load(weights)  # é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰
        return model  # ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™

    def get_validator(self):
        # YOLOãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ç”¨ã®DetectionValidatorã‚’è¿”ã—ã¾ã™ã€‚
        self.loss_names = "box_loss", "cls_loss", "dfl_loss" , "  feature_loss" # æå¤±åã‚’è¨­å®š
        #self.loss_names = "box_loss", "cls_loss", "dfl_loss" 
        return yolo.detect.DetectionValidator(
            self.test_loader, save_dir=self.save_dir, args=copy(self.args), _callbacks=self.callbacks
        )  # DetectionValidatorã‚’è¿”ã™

    def label_loss_items(self, loss_items=None, prefix="train"):
        # ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æå¤±ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ãƒ³ã‚½ãƒ«ã‚’å«ã‚€æå¤±dictã‚’è¿”ã—ã¾ã™ã€‚
        # åˆ†é¡ã«ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ãŒã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨æ¤œå‡ºã«ã¯å¿…è¦ã§ã™
        keys = [f"{prefix}/{x}" for x in self.loss_names]  # æå¤±åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        if loss_items is not None:  # æå¤±ã‚¢ã‚¤ãƒ†ãƒ ãŒNoneã§ãªã„å ´åˆ
            loss_items = [round(float(x), 5) for x in loss_items]  # convert tensors to 5 decimal place floatsã€‚ãƒ†ãƒ³ã‚½ãƒ«ã‚’5æ¡ã®æµ®å‹•å°æ•°ç‚¹æ•°ã«å¤‰æ›
            return dict(zip(keys, loss_items))  # æå¤±è¾æ›¸ã‚’è¿”ã™
        else:  # æå¤±ã‚¢ã‚¤ãƒ†ãƒ ãŒNoneã®å ´åˆ
            return keys  # æå¤±åãƒªã‚¹ãƒˆã‚’è¿”ã™

    def progress_string(self):
        """Returns a formatted string of training progress with epoch, GPU memory, loss, instances and size."""
        # ã‚¨ãƒãƒƒã‚¯ã€GPUãƒ¡ãƒ¢ãƒªã€æå¤±ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€ãŠã‚ˆã³ã‚µã‚¤ã‚ºã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®é€²è¡ŒçŠ¶æ³ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—ã‚’è¿”ã—ã¾ã™ã€‚
        return ("\n" + "%11s" * (4 + len(self.loss_names))) % (  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—ã‚’ä½œæˆ
            "Epoch",  # ã‚¨ãƒãƒƒã‚¯
            "GPU_mem",  # GPUãƒ¡ãƒ¢ãƒª
            *self.loss_names,  # æå¤±å
            "Instances",  # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°
            "Size",  # ã‚µã‚¤ã‚º
        )

    def plot_training_samples(self, batch, ni):
        """Plots training samples with their annotations."""
        # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚
        plot_images(
            images=batch["img"],  # ç”»åƒãƒ‡ãƒ¼ã‚¿
            batch_idx=batch["batch_idx"],  # ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            cls=batch["cls"].squeeze(-1),  # ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«
            bboxes=batch["bboxes"],  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            paths=batch["im_file"],  # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            fname=self.save_dir / f"train_batch{ni}.jpg",  # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å
            on_plot=self.on_plot,  # ãƒ—ãƒ­ãƒƒãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        )

    def plot_metrics(self):
        """Plots metrics from a CSV file."""
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚
        plot_results(file=self.csv, on_plot=self.on_plot)  # save results.pngã€‚results.pngã‚’ä¿å­˜

    def plot_training_labels(self):
        """Create a labeled training plot of the YOLO model."""
        # YOLOãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
        boxes = np.concatenate([lb["bboxes"] for lb in self.train_loader.dataset.labels], 0)  # ã™ã¹ã¦ã®ãƒ©ãƒ™ãƒ«ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’çµåˆ
        cls = np.concatenate([lb["cls"] for lb in self.train_loader.dataset.labels], 0)  # ã™ã¹ã¦ã®ãƒ©ãƒ™ãƒ«ã®ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’çµåˆ
        plot_labels(boxes, cls.squeeze(), names=self.data["names"], save_dir=self.save_dir, on_plot=self.on_plot)  # ãƒ©ãƒ™ãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆ